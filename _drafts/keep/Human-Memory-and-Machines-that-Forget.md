---
id: 77
title: Human Memory and Machines that Forget
date: 2013-03-25T21:18:19-07:00
author: Louis Potok
layout: revision
guid: http://louispotok.com/16-revision-7/
permalink: /?p=77
---
**First question: How often do you look back through old photos?**

<p style="padding-left: 30px;">
  <em>One-and-a-half-th question: how does it make you feel?</em>
</p>

**Second question: If you were designing your best friend from scratch, would you give him a really good memory?** I have friends who remember stories much better than I do, and it&#8217;s a real mixed blessing.[^1]

[^1]: At the very least it feels like they remember better than I do. But being reminded of a story is more memorable than telling someone a story they had forgotten, so there&rsquo;s probably some availability bias in that statement: buyer beware. Also, how should you parse the statement "as far as I remember, in most situations I have the worse memory"?


When a friend reminds me of a time when I was brave or charming or kind, I may come to remember it in half-light or in stop-motion or I might just take their word for it. Most of life is unmemorable, and what matters is the balance of good memories to bad memories&#8211;not the total quantity of memories. This story has made the good part of my life longer, tipped the balance in my better half&#8217;s favor. Moreover I feel flattered that my friend&#8217;s idea of me includes this memory. On the other hand, sometimes I hear stories that I was glad to forget the first time around. Confronting unpleasant truths can be good for you, but it is not fun and often it is not even good for you.

**Third question: what kind of memory should machines have? **The obvious answer is &#8220;as much and as accessible as possible&#8221; but I think the situation is more complicated. I use Amazon Wishlist to remember books I want to read, but in general not every application needs to perfectly remember (or remind you of) everything. In [an earlier post](http://louispotok.com/should-robots-have-emotions/) I talked about the question of machine emotion, and I&#8217;ll use the same arguments here (in a different order).

_Robots should store/use/display memory in a way that makes life better for people_. _Sometimes this entails limiting the information used._ Examples:

  * <span style="line-height: 1.714285714; font-size: 1rem;" data-mce-mark="1">I can easily imagine Yelp rolling out the following feature: &#8220;Last time you checked in here, you ordered Mapo Tofu, Dry Fried Beef and Spicy Green Shoots. You didn&#8217;t like the Dry Fried Beef, but the other two dishes were great.&#8221; But this seems like it makes life worse: I&#8217;d probably be happier/better off with variety and uncertainty.</span>
  * <span style="line-height: 1.714285714; font-size: 1rem;">Imagine a word processor that used Markov chains to suggest the next word you should use in a sentence. If it worked </span>
  * <span style="line-height: 1.714285714; font-size: 1rem;"> You haven&#8217;t been there much, but a few weeks ago Mike recommended  You go on Facebook and&#8211;BIG NEWS&#8211;your HS flame is now engaged. You</span>

<span style="line-height: 1.714285714; font-size: 1rem;" data-mce-mark="1">Remember that we have to interact with machines, and remember the first two (and a half) questions were.</span>

It&#8217;s only natural to design a machine that fixes There are two closely related intuitions that lead us astray when it comes to designing technology. The general one is that more&#8211;size, speed, capacity, choice&#8211;is always better.[^2]  And, specifically, the most important dimensions are those in which we feel we ourselves need to improve[^3].

[^2]: Is this a universal human tendency or just late capitalism?
[^3] this is marginal vs. absolute thinking
One major

Sometimes, though, we find that we had the right solution all along. We thought that the problem with humans is too much emotion, not enough cognition. So when we are designing fake humans (robots), we build them without emotions. Donald Norman, in Emotional Design, suggests that we do the opposite both because it will be important for us to relate to and also because it will make them more effective (coffeepot example). We should start thinking the same way about memory. It is very important, for social relationships to function, for memory to be on the same level among participants. So our machines should forget things like we do. moreover memory is like attention: there are many possible things to &#8220;remember&#8221; = take into account, so need some way to prioritize/subset.

